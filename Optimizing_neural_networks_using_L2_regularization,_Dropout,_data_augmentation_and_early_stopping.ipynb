{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm3VJNdCHtO3cp9L61S8cR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiraghava/Deep_learning/blob/main/Optimizing_neural_networks_using_L2_regularization%2C_Dropout%2C_data_augmentation_and_early_stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw00z9fHrf5e",
        "outputId": "737d3c43-6e03-48dc-e453-c1229864dbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - 61s 76ms/step - loss: 1.7724 - accuracy: 0.1173 - val_loss: 1.5193 - val_accuracy: 0.1143\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 1.4717 - accuracy: 0.1004 - val_loss: 1.2515 - val_accuracy: 0.1059\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 1.3583 - accuracy: 0.0974 - val_loss: 1.1609 - val_accuracy: 0.1097\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 1.2954 - accuracy: 0.0976 - val_loss: 1.1566 - val_accuracy: 0.1274\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.2555 - accuracy: 0.0979 - val_loss: 1.1552 - val_accuracy: 0.0863\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.2191 - accuracy: 0.0961 - val_loss: 1.0978 - val_accuracy: 0.0959\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.1855 - accuracy: 0.0969 - val_loss: 1.1419 - val_accuracy: 0.0862\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.1661 - accuracy: 0.0977 - val_loss: 1.1004 - val_accuracy: 0.1385\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.1417 - accuracy: 0.0979 - val_loss: 0.9748 - val_accuracy: 0.1150\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.1249 - accuracy: 0.0985 - val_loss: 1.0206 - val_accuracy: 0.0967\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.1067 - accuracy: 0.0994 - val_loss: 0.9780 - val_accuracy: 0.0952\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.0909 - accuracy: 0.1000 - val_loss: 0.9736 - val_accuracy: 0.0649\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.0801 - accuracy: 0.1002 - val_loss: 0.9799 - val_accuracy: 0.0969\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 1.0715 - accuracy: 0.0997 - val_loss: 0.9139 - val_accuracy: 0.1219\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.0663 - accuracy: 0.0993 - val_loss: 0.9821 - val_accuracy: 0.0870\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.0573 - accuracy: 0.0998 - val_loss: 0.9162 - val_accuracy: 0.0957\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.0415 - accuracy: 0.1005 - val_loss: 0.9322 - val_accuracy: 0.0898\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 1.0453 - accuracy: 0.1010 - val_loss: 0.9186 - val_accuracy: 0.0918\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.0369 - accuracy: 0.0996 - val_loss: 0.9492 - val_accuracy: 0.1149\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.0236 - accuracy: 0.0999 - val_loss: 0.8951 - val_accuracy: 0.1094\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.0224 - accuracy: 0.1013 - val_loss: 0.8797 - val_accuracy: 0.0990\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 60s 76ms/step - loss: 1.0159 - accuracy: 0.1000 - val_loss: 0.8552 - val_accuracy: 0.1143\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 1.0093 - accuracy: 0.1003 - val_loss: 0.8763 - val_accuracy: 0.0898\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 1.0008 - accuracy: 0.1009 - val_loss: 0.8429 - val_accuracy: 0.1075\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 0.9935 - accuracy: 0.1002 - val_loss: 0.8882 - val_accuracy: 0.0956\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 0.9930 - accuracy: 0.1007 - val_loss: 0.8682 - val_accuracy: 0.1022\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 0.9928 - accuracy: 0.1007 - val_loss: 0.8711 - val_accuracy: 0.1112\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 0.9816 - accuracy: 0.1016 - val_loss: 0.8658 - val_accuracy: 0.1088\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 0.9843 - accuracy: 0.1010 - val_loss: 0.8643 - val_accuracy: 0.1125\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.9790 - accuracy: 0.1016 - val_loss: 0.8627 - val_accuracy: 0.1162\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 0.9714 - accuracy: 0.1021 - val_loss: 0.8535 - val_accuracy: 0.0959\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.9625 - accuracy: 0.1019 - val_loss: 0.9093 - val_accuracy: 0.1051\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 0.9682 - accuracy: 0.1016 - val_loss: 0.8690 - val_accuracy: 0.1248\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.9644 - accuracy: 0.1002 - val_loss: 0.8441 - val_accuracy: 0.0956\n",
            "313/313 - 3s - loss: 0.8429 - accuracy: 0.1075 - 3s/epoch - 10ms/step\n",
            "\n",
            "Test accuracy: 0.10750000178813934\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(1e-4), input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),  # Dropout layer with a dropout rate of 0.5\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with data augmentation and early stopping\n",
        "history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "                    epochs=100,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"\\nTest accuracy:\", test_acc)\n"
      ]
    }
  ]
}